{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SKwP6xqo6b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.7.2-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "     -------------------------------------- 384.9/384.9 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 exceptiongroup-1.0.4 h11-0.14.0 outcome-1.2.0 selenium-4.7.2 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# https://blog.devgenius.io/how-to-build-a-scraping-tool-for-linkedin-in-7-minutes-tool-data-science-csv-selenium-beautifulsoup-python-a673f12ac579\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QqvrsGn36KDD"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job name: Data Scientist\n"
     ]
    }
   ],
   "source": [
    "job_name = input(\"Enter the job name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job location: United States\n"
     ]
    }
   ],
   "source": [
    "country_name =input(\"Enter the job location: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "FqYsJGMi6ops",
    "outputId": "ab5777d2-c7fd-457f-a629-592c36ae2390"
   },
   "outputs": [],
   "source": [
    "# job_name = \"Data Scientist\"\n",
    "# country_name = \"United States\"\n",
    "\n",
    "job_url =\"\";\n",
    "for item in job_name.split(\" \"):\n",
    "    if item != job_name.split(\" \")[-1]:\n",
    "        job_url = job_url + item + \"%20\"\n",
    "    else:\n",
    "        job_url = job_url + item\n",
    "\n",
    "country_url =\"\";\n",
    "for item in country_name.split(\" \"):\n",
    "    if item != country_name.split(\" \")[-1]:\n",
    "        country_url = country_url + item + \"%20\"\n",
    "    else:\n",
    "        country_url = country_url + item\n",
    "\n",
    "url = \"https://www.linkedin.com/jobs/search?keywords={0}&location={1}&geoId=103644278&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\".format(job_url,country_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "G9weroyz-0LX",
    "outputId": "189a004a-12f9-4514-9906-4c2c850c947d"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from selenium import webdriver\n",
    "# def main():\n",
    "#     a = webdriver.Chrome()\n",
    "#     a.get('https://www.google.com')\n",
    "#     time.sleep(5)\n",
    "#     a.quit()\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "T3crarDT68ib",
    "outputId": "cc131011-6dde-4050-eefe-a387914beaa2"
   },
   "outputs": [],
   "source": [
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome(\"ChromeDriver_Path/chromedriver\")\n",
    "# Opening the url we have just defined in our browser\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308000\n"
     ]
    }
   ],
   "source": [
    "#We find how many jobs are offered.\n",
    "jobs_num = driver.find_element(By.CSS_SELECTOR,\"h1>span\").get_attribute(\"innerText\")\n",
    "if len(jobs_num.split(',')) > 1:\n",
    "    jobs_num = int(jobs_num.split(',')[0])*1000\n",
    "else:\n",
    "    jobs_num = int(jobs_num)\n",
    "\n",
    "jobs_num   = int(jobs_num)\n",
    "print(jobs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the numbers of jobs needed: 100\n"
     ]
    }
   ],
   "source": [
    "numbers = input(\"Enter the numbers of jobs needed: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current at:  52 Percentage at:  103.921568627451 % %\r"
     ]
    }
   ],
   "source": [
    "#We create a while loop to browse all jobs. \n",
    "numbers = int(numbers)\n",
    "i = 2\n",
    "while i <= int(numbers/2)+1:\n",
    "    #We keep scrollind down to the end of the view.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    i = i + 1\n",
    "    print(\"Current at: \", i, \"Percentage at: \", ((i+1)/(int(numbers/2)+1))*100, \"%\",end=\"\\r\")\n",
    "    try:\n",
    "        #We try to click on the load more results buttons in case it is already displayed.\n",
    "        infinite_scroller_button = driver.find_element(By.XPATH, \".//button[@aria-label='Load more results']\")\n",
    "        infinite_scroller_button.click()\n",
    "        time.sleep(0.1)\n",
    "    except:\n",
    "        #If there is no button, there will be an error, so we keep scrolling down.\n",
    "        time.sleep(0.1)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amicus</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Farmer's Fridge</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>UMortgage</td>\n",
       "      <td>Greater Philadelphia</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/jr-data-sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist, Jr.</td>\n",
       "      <td>Altamira Technologies Corporation</td>\n",
       "      <td>Hurlburt Field, FL</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Full Time</td>\n",
       "      <td>Bardess Group Ltd</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Manager, Data Scientist, Digital Analytics</td>\n",
       "      <td>Panera Bread</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/manager-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Medical Solutions</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Data Scientist / Analytics Engineer</td>\n",
       "      <td>Alston &amp; Bird</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Idexcel</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>Compunnel Inc.</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/research-da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job Title  \\\n",
       "0                                Data Scientist   \n",
       "1                                Data Scientist   \n",
       "2                            Jr. Data Scientist   \n",
       "3                           Data Scientist, Jr.   \n",
       "4                      Data Scientist Full Time   \n",
       "..                                          ...   \n",
       "170  Manager, Data Scientist, Digital Analytics   \n",
       "171                            Data Scientist I   \n",
       "172         Data Scientist / Analytics Engineer   \n",
       "173                              Data Scientist   \n",
       "174                     Research Data Scientist   \n",
       "\n",
       "                               Company              Location        Date  \\\n",
       "0                               Amicus          New York, NY  2022-12-06   \n",
       "1                      Farmer's Fridge           Chicago, IL  2022-12-15   \n",
       "2                            UMortgage  Greater Philadelphia  2022-12-09   \n",
       "3    Altamira Technologies Corporation    Hurlburt Field, FL  2022-12-14   \n",
       "4                    Bardess Group Ltd          New York, NY  2022-12-06   \n",
       "..                                 ...                   ...         ...   \n",
       "170                       Panera Bread         United States  2022-12-12   \n",
       "171                  Medical Solutions         United States  2022-12-15   \n",
       "172                      Alston & Bird           Raleigh, NC  2022-12-12   \n",
       "173                            Idexcel           Herndon, VA  2022-12-15   \n",
       "174                     Compunnel Inc.         Cambridge, MA  2022-12-08   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "1    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "2    https://www.linkedin.com/jobs/view/jr-data-sci...  \n",
       "3    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "4    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "..                                                 ...  \n",
       "170  https://www.linkedin.com/jobs/view/manager-dat...  \n",
       "171  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "172  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "173  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "174  https://www.linkedin.com/jobs/view/research-da...  \n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We get a list containing all jobs that we have found.\n",
    "job_lists = driver.find_element(By.CLASS_NAME,\"jobs-search__results-list\")\n",
    "jobs = job_lists.find_elements(By.TAG_NAME,\"li\") # return a list\n",
    "\n",
    "#We declare void list to keep track of all obtaind data.\n",
    "job_title_list = []\n",
    "company_name_list = []\n",
    "location_list = []\n",
    "date_list = []\n",
    "job_link_list = []\n",
    "\n",
    "#We loof over every job and obtain all the wanted info.\n",
    "for job in jobs:\n",
    "    #job_title\n",
    "    job_title = job.find_element(By.CSS_SELECTOR,\"h3\").get_attribute(\"innerText\")\n",
    "    job_title_list.append(job_title)\n",
    "    \n",
    "    #company_name\n",
    "    company_name = job.find_element(By.CSS_SELECTOR,\"h4\").get_attribute(\"innerText\")\n",
    "    company_name_list.append(company_name)\n",
    "    \n",
    "    #location\n",
    "    location = job.find_element(By.CSS_SELECTOR,\"div>div>span\").get_attribute(\"innerText\")\n",
    "    location_list.append(location)\n",
    "    \n",
    "    #date\n",
    "    date = job.find_element(By.CSS_SELECTOR,\"div>div>time\").get_attribute(\"datetime\")\n",
    "    date_list.append(date)\n",
    "    \n",
    "    #job_link\n",
    "    job_link = job.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"href\")\n",
    "    job_link_list.append(job_link)\n",
    "\n",
    "jobs_df = pd.DataFrame({'Job Title': job_title_list,\n",
    "              'Company': company_name_list,\n",
    "              'Location': location_list,\n",
    "              'Date': date_list,\n",
    "              'Link': job_link_list\n",
    "            })\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "jobs_df.to_csv('Sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
